{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save the MNSIT dataset\n",
    "PATH = '../data/'\n",
    "\n",
    "# a variable signifying whether to download the data or use a predownloaded one\n",
    "DOWNLOAD = False\n",
    "\n",
    "# download the training dataset, if the data is present don't forget to remove the download parameter\n",
    "# also transform the images into tensors, originaly they are PIL objects\n",
    "train_set = MNIST(root=PATH, download=DOWNLOAD, transform=transforms.ToTensor())\n",
    "\n",
    "# download the testing dataset, if the data is present don't forget to remove the download parameter\n",
    "# also transform the images into tensors, originaly they are PIL objects\n",
    "test_set = MNIST(root=PATH, download=DOWNLOAD, train=False, transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here the images should be converted from PIL(Pilow) objects to tensor, which is a multidimensional array of numbers often in a rectangular shape. For simplicity of understanding you can consider it as an array of matrics.\n",
    "\n",
    "Note: anything can be a tensor, even 1 singluar number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 training data points\n",
      "10000 testing data points\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_set)} training data points\")\n",
    "print(f\"{len(test_set)} testing data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is a collection of tuples with the first index being the pillow object of the number and the second index being the label of that number. This is true for both the training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Define the model by creating a class that will be a subclass of torch.nn.Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A one linear layer Neural Net for training on MNIST dataset.\n",
    "    It expects the images to be of 28 X 28 dimension, which should be flattend making them one linear input with a length of 784.\n",
    "    The outputs it gives are one of 10 classes, 0 - 9\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Define loss/optimizer for the neural network\n",
    "\n",
    "The SGD(Stochastic Gradient Descent) is used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialze the optimizer\n",
    "sgd_optimizer = torch.optim.SGD(\n",
    "    lr=0.1, # the learning rate\n",
    "    params=model.parameters()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.1\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define data loaders with batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.utils.data.dataloader\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# use pytorch for loading the training data in batches\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# use pytorch for loading the testing data in batches\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a function that is used for infering/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: torch.nn.Module, test_data_loader: torch.utils.data.DataLoader):\n",
    "    \"\"\"\n",
    "    A function that obtains the accuracy of a model over an MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        model(torch.nn.Module): the model to be tested\n",
    "        test_data_loader(torch.utils.data.DataLoader): a data loader for the dataset you want to test the model over\n",
    "\n",
    "    Returns:\n",
    "        accuracy(tensor): the accuracy of the model\n",
    "    \"\"\"\n",
    "    for batch in test_data_loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        # a list for holding accuracies for each batch\n",
    "        accuracies = []\n",
    "\n",
    "        # reshape the images\n",
    "        images = images.view(-1, 784)\n",
    "        with torch.no_grad():\n",
    "            # obtain the predictions\n",
    "            predictions = model(images)\n",
    "            label_predictions = predictions.argmax(dim=1)\n",
    "            \n",
    "            # calculate the accuracy\n",
    "            correct_predictions = label_predictions == labels\n",
    "            accuracy = sum(correct_predictions) / len(label_predictions)\n",
    "\n",
    "            # add the accuracy to the list\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "        # calculate the average accuracy\n",
    "        avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "        return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0703)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model=model, test_data_loader=test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of the untrained model is about 6.25%. If we increate the batch size it will be closer to 10% because at this point the model is just having a random guess, witch a chance of getting the rigth answer 1 out of 10 times, and increasing the sample size will get you closer to 10%. You can check this out by adjusting the batch size on previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model: torch.nn.Module, image: torch.Tensor, labels: torch.Tensor, optimizer: torch.optim.Optimizer):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # define tests\n",
    "    assert type(model) == Net\n",
    "    assert type(image) == torch.Tensor\n",
    "    assert type(labels) == torch.Tensor\n",
    "    assert image.shape[0] == labels.shape[0]\n",
    "\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # predict using the model\n",
    "    predictions = model(image)\n",
    "    label_predictions = predictions.argmax(dim=1)\n",
    "\n",
    "    # calculate loss\n",
    "    loss_calculatro = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_calculatro(predictions, labels)\n",
    "    \n",
    "    # calculate the accuracy\n",
    "    correct_predictions = label_predictions == labels\n",
    "    accuracy = sum(correct_predictions) / len(label_predictions)\n",
    "    \n",
    "    # back propagate the lost\n",
    "    loss.backward()\n",
    "\n",
    "    # upadte the weights using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def train_epoch(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    loss_progression = []\n",
    "    accuracy_progression = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1, 784)\n",
    "        \n",
    "        loss, accuracy = train_batch(model=model, image=images, labels=labels, optimizer=optimizer)\n",
    "        \n",
    "        loss_progression.append(loss)\n",
    "        accuracy_progression.append(accuracy)\n",
    "\n",
    "    avg_loss = sum(loss_progression) / len(loss_progression)\n",
    "    avg_accuracy = sum(accuracy_progression) / len(accuracy_progression)\n",
    "\n",
    "    return avg_loss, avg_accuracy, loss_progression, accuracy_progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "model_copy = copy.deepcopy(model)\n",
    "avg_loss, avg_accuracy, loss_history, accuracy_history = train_epoch(model=model_copy, data_loader=train_data_loader, optimizer=sgd_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss is: 2.350289821624756\n",
      "The average accuracy is: 0.051439233124256134\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average loss is: {avg_loss}\")\n",
    "print(f\"The average accuracy is: {avg_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After training the model has achieved an accuracy of 89.8% and a loss of 0.566.\n",
    "- This is over one epoch, one iteration over the dataset. So next let us train it over more than 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 => train_loss: 0.5760444402694702 | train_accuracy: 0.8581923246383667 | test_accuracy: 0.9375\n",
      "Epoch 2/10 => train_loss: 0.3744281232357025 | train_accuracy: 0.8974713683128357 | test_accuracy: 0.9453125\n",
      "Epoch 3/10 => train_loss: 0.3426187336444855 | train_accuracy: 0.904795229434967 | test_accuracy: 0.9453125\n",
      "Epoch 4/10 => train_loss: 0.3260417878627777 | train_accuracy: 0.9092872738838196 | test_accuracy: 0.9375\n",
      "Epoch 5/10 => train_loss: 0.31539374589920044 | train_accuracy: 0.9121135473251343 | test_accuracy: 0.9375\n",
      "Epoch 6/10 => train_loss: 0.3077022433280945 | train_accuracy: 0.9146566390991211 | test_accuracy: 0.9453125\n",
      "Epoch 7/10 => train_loss: 0.3020157516002655 | train_accuracy: 0.9162335395812988 | test_accuracy: 0.9453125\n",
      "Epoch 8/10 => train_loss: 0.2971782088279724 | train_accuracy: 0.9176272749900818 | test_accuracy: 0.9375\n",
      "Epoch 9/10 => train_loss: 0.29349759221076965 | train_accuracy: 0.9180215001106262 | test_accuracy: 0.9453125\n",
      "Epoch 10/10 => train_loss: 0.2902572751045227 | train_accuracy: 0.9190709590911865 | test_accuracy: 0.9453125\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # lists for holding training history\n",
    "    test_accuracy_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_loss_history = []\n",
    "\n",
    "    # train the model \n",
    "    train_loss, train_accuracy, loss_history, accuracy_history = train_epoch(model=model, data_loader=train_data_loader, optimizer=sgd_optimizer)\n",
    "    \n",
    "    # get test accuracy\n",
    "    accuracy = test_model(model=model, test_data_loader=test_data_loader)\n",
    "\n",
    "    # add the training history\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_loss_history = [*train_loss_history, *loss_history]\n",
    "\n",
    "    # print out epoch progression\n",
    "    print(f\"Epoch {epoch+1}/{epochs} => train_loss: {train_loss} | train_accuracy: {train_accuracy} | test_accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
